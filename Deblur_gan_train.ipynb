{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this cell for Google colab only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/hassansadiq1/Deblur_GAN.git\n",
    "import os\n",
    "os.chdir(\"Deblur_GAN/\")\n",
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob, cv2, os\n",
    "import datetime\n",
    "import tqdm\n",
    "\n",
    "#from deblurgan.utils import write_log\n",
    "from losses import wasserstein_loss, perceptual_loss\n",
    "from model import generator_model, discriminator_model, generator_containing_discriminator_multiple_outputs\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "#for saving weights\n",
    "BASE_DIR = 'weights/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images from input directory\n",
    "def load_images(images_path):\n",
    "    X_images = []\n",
    "    for img in images_path:\n",
    "      X_images.append(cv2.resize(cv2.imread(img), input_shape[:-1]))\n",
    "    X_images = np.array(X_images)\n",
    "    #Preprocessing i.e normalizing data\n",
    "    X_images = (X_images - 127.5) / 127.5\n",
    "    return X_images\n",
    "\n",
    "# Saving weights after each iteration\n",
    "def save_all_weights(d, g, epoch_number, current_loss):\n",
    "    now = datetime.datetime.now()\n",
    "    save_dir = os.path.join(BASE_DIR, '{}{}'.format(now.month, now.day))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    g.save_weights(os.path.join(save_dir, 'generator_{}_{}.h5'.format(epoch_number, current_loss)), True)\n",
    "    d.save_weights(os.path.join(save_dir, 'discriminator_{}.h5'.format(epoch_number)), True)\n",
    "\n",
    "# Training of model\n",
    "def train_multiple_outputs(images_path, batch_size, epoch_num, critic_updates=5):\n",
    "    x_path = glob.glob(images_path + \"/blurred/*\")\n",
    "    y_path = glob.glob(images_path + \"/unblurred/*\")\n",
    "    x_path.sort(); y_path.sort();\n",
    "    x_train = load_images(x_path)\n",
    "    y_train = load_images(y_path)\n",
    "\n",
    "    g = generator_model(input_shape)\n",
    "    d = discriminator_model(input_shape)\n",
    "    d_on_g = generator_containing_discriminator_multiple_outputs(g, d, input_shape)\n",
    "\n",
    "    d_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    d_on_g_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "    d.trainable = True\n",
    "    d.compile(optimizer=d_opt, loss=wasserstein_loss)\n",
    "    d.trainable = False\n",
    "    loss = [perceptual_loss, wasserstein_loss]\n",
    "    loss_weights = [100, 1]\n",
    "    d_on_g.compile(optimizer=d_on_g_opt, loss=loss, loss_weights=loss_weights)\n",
    "    d.trainable = True\n",
    "\n",
    "    output_true_batch, output_false_batch = np.ones((batch_size, 1)), -np.ones((batch_size, 1))\n",
    "\n",
    "    tensorboard_callback = TensorBoard(\"../\")\n",
    "    print(\"returning\")\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(epoch_num)):\n",
    "        permutated_indexes = np.random.permutation(x_train.shape[0])\n",
    "\n",
    "        d_losses = []\n",
    "        d_on_g_losses = []\n",
    "        for index in range(int(x_train.shape[0] / batch_size)):\n",
    "            batch_indexes = permutated_indexes[index*batch_size:(index+1)*batch_size]\n",
    "            image_blur_batch = x_train[batch_indexes]\n",
    "            image_full_batch = y_train[batch_indexes]\n",
    "\n",
    "            generated_images = g.predict(x=image_blur_batch, batch_size=batch_size)\n",
    "\n",
    "            for _ in range(critic_updates):\n",
    "                d_loss_real = d.train_on_batch(image_full_batch, output_true_batch)\n",
    "                d_loss_fake = d.train_on_batch(generated_images, output_false_batch)\n",
    "                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "                d_losses.append(d_loss)\n",
    "\n",
    "            d.trainable = False\n",
    "\n",
    "            d_on_g_loss = d_on_g.train_on_batch(image_blur_batch, [image_full_batch, output_true_batch])\n",
    "            d_on_g_losses.append(d_on_g_loss)\n",
    "\n",
    "            d.trainable = True\n",
    "\n",
    "        # write_log(tensorboard_callback, ['g_loss', 'd_on_g_loss'], [np.mean(d_losses), np.mean(d_on_g_losses)], epoch_num)\n",
    "        print(np.mean(d_losses), np.mean(d_on_g_losses))\n",
    "        with open('log.txt', 'a+') as f:\n",
    "            f.write('{} - {} - {}\\n'.format(epoch, np.mean(d_losses), np.mean(d_on_g_losses)))\n",
    "\n",
    "        save_all_weights(d, g, epoch, int(np.mean(d_on_g_losses)))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Parameters accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters for our model\n",
    "input_shape = (256,256,3)\n",
    "batch_size = 1\n",
    "epochs = 1\n",
    "input_directory = \"train_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training of model with the parameters provided above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_multiple_outputs(input_directory, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hassan",
   "language": "python",
   "name": "hassan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
